# What-Is-Data-Quality

Data quality is the application of quality management techniques to data to ensure that it meets the needs of the organization. High quality data is data that has been deemed suitable for its intended purpose.

Data quality issues can include data duplication, incompletion, inconsistent data and incorrect data.

<a href="https://firsteigen.com/blog/establish-autonomous-data-observability-and-trustability-for-aws-glue-pipeline-in-60-seconds/">Data quality</a> analysts perform data quality assessments. They assess and interpret every data quality metric and give organizations a percentage to indicate the accuracy of their data. Low data quality scores can indicate poor data quality. This is misleading and could lead to poor decision-making that could harm the organization.

Data governance is about establishing and following a set of agreed-upon rules and standards that govern all data within an organization. Data governance must harmonize data from different sources, establish and monitor data usage policies and eliminate inconsistencies or inaccuracies that could negatively impact data analytics accuracy.


**Data Quality Dimensions**


What metrics are used to measure data quality? Six dimensions are important in measuring data quality: accuracy and completeness, consistency validity uniqueness, validity, validity, timeliness, validity and consistency.

**Accuracy:** Data should reflect real-world scenarios. Verifiable sources can confirm the accuracy of the data.


**Completion:** Completeness refers to the data's ability and effectiveness in delivering all required values.


**Consistency:** Data consistent refers to data's uniformity as it moves between networks and applications. Data values that are stored in different locations should not be contradictory.


**Validity:** Data must be collected in accordance with established business rules and parameters. It should conform to the correct format and fall within the appropriate range.


**Uniqueness:** Uniqueness ensures that there are no duplicates or overlapping values across all data sets. A low score on uniqueness can be corrected by data cleansing and deduplication.


**Timing:** Temporary data means data that is readily available when it's needed. Data can be updated immediately to ensure it is always available.
